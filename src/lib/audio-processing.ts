/**\n * Advanced audio processing utilities for AudioSphere\n * Handles audio streaming, quality adaptation, and performance optimization\n */\n\nexport interface AudioQuality {\n  bitrate: number;\n  sampleRate: number;\n  channels: number;\n  format: 'mp3' | 'aac' | 'ogg' | 'webm';\n  label: string;\n}\n\nexport interface AudioTrack {\n  id: number;\n  title: string;\n  artist: string;\n  duration: number;\n  sources: {\n    low: string;\n    medium: string;\n    high: string;\n    lossless?: string;\n  };\n  metadata?: {\n    album?: string;\n    year?: number;\n    genre?: string;\n    artwork?: string;\n  };\n}\n\nexport interface AudioPlayerState {\n  currentTime: number;\n  duration: number;\n  buffered: TimeRanges | null;\n  loading: boolean;\n  error: string | null;\n  quality: keyof AudioTrack['sources'];\n  volume: number;\n  muted: boolean;\n  playbackRate: number;\n}\n\n/**\n * Audio quality presets for different network conditions\n */\nexport const AUDIO_QUALITIES: Record<string, AudioQuality> = {\n  low: {\n    bitrate: 128,\n    sampleRate: 44100,\n    channels: 2,\n    format: 'mp3',\n    label: 'Low (128kbps)',\n  },\n  medium: {\n    bitrate: 256,\n    sampleRate: 44100,\n    channels: 2,\n    format: 'mp3',\n    label: 'Medium (256kbps)',\n  },\n  high: {\n    bitrate: 320,\n    sampleRate: 44100,\n    channels: 2,\n    format: 'mp3',\n    label: 'High (320kbps)',\n  },\n  lossless: {\n    bitrate: 1411,\n    sampleRate: 44100,\n    channels: 2,\n    format: 'webm',\n    label: 'Lossless (FLAC)',\n  },\n};\n\n/**\n * Advanced audio player class with streaming optimization\n */\nexport class AudioStreamingPlayer {\n  private audio: HTMLAudioElement;\n  private currentTrack: AudioTrack | null = null;\n  private eventListeners: Map<string, Function[]> = new Map();\n  private preloadedTracks: Map<number, HTMLAudioElement> = new Map();\n  private qualityAdapter: QualityAdapter;\n  private crossfader: AudioCrossfader;\n  private bufferManager: AudioBufferManager;\n  private networkMonitor: NetworkMonitor;\n\n  constructor() {\n    this.audio = new Audio();\n    this.qualityAdapter = new QualityAdapter();\n    this.crossfader = new AudioCrossfader();\n    this.bufferManager = new AudioBufferManager();\n    this.networkMonitor = new NetworkMonitor();\n    \n    this.setupEventListeners();\n    this.enableCrossfade(true);\n  }\n\n  /**\n   * Load and play a track with quality adaptation\n   */\n  async loadTrack(track: AudioTrack, autoPlay = false): Promise<void> {\n    this.currentTrack = track;\n    \n    // Determine optimal quality based on network conditions\n    const optimalQuality = await this.qualityAdapter.getOptimalQuality(track);\n    const audioUrl = track.sources[optimalQuality];\n    \n    if (!audioUrl) {\n      throw new Error(`Audio source not available for quality: ${optimalQuality}`);\n    }\n\n    // Set up audio element\n    this.audio.src = audioUrl;\n    this.audio.preload = 'auto';\n    \n    // Set metadata for media session API\n    this.setMediaSessionMetadata(track);\n    \n    // Enable buffer management\n    this.bufferManager.manage(this.audio);\n    \n    if (autoPlay) {\n      await this.play();\n    }\n    \n    this.emit('trackLoaded', { track, quality: optimalQuality });\n  }\n\n  /**\n   * Play audio with crossfade support\n   */\n  async play(): Promise<void> {\n    try {\n      if (this.crossfader.isEnabled()) {\n        await this.crossfader.fadeIn(this.audio);\n      } else {\n        await this.audio.play();\n      }\n      this.emit('play');\n    } catch (error) {\n      this.emit('error', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Pause audio with crossfade support\n   */\n  async pause(): Promise<void> {\n    if (this.crossfader.isEnabled()) {\n      await this.crossfader.fadeOut(this.audio);\n    } else {\n      this.audio.pause();\n    }\n    this.emit('pause');\n  }\n\n  /**\n   * Seek to specific time\n   */\n  seek(time: number): void {\n    this.audio.currentTime = Math.max(0, Math.min(time, this.audio.duration || 0));\n    this.emit('seek', { time });\n  }\n\n  /**\n   * Change audio quality dynamically\n   */\n  async changeQuality(quality: keyof AudioTrack['sources']): Promise<void> {\n    if (!this.currentTrack || !this.currentTrack.sources[quality]) {\n      throw new Error(`Quality ${quality} not available`);\n    }\n\n    const currentTime = this.audio.currentTime;\n    const wasPlaying = !this.audio.paused;\n    \n    // Load new quality\n    this.audio.src = this.currentTrack.sources[quality];\n    this.audio.currentTime = currentTime;\n    \n    if (wasPlaying) {\n      await this.play();\n    }\n    \n    this.emit('qualityChanged', { quality });\n  }\n\n  /**\n   * Preload next track for seamless playback\n   */\n  preloadTrack(track: AudioTrack): void {\n    if (this.preloadedTracks.has(track.id)) {\n      return;\n    }\n\n    const audio = new Audio();\n    const quality = this.qualityAdapter.getCurrentQuality();\n    audio.src = track.sources[quality] || track.sources.medium;\n    audio.preload = 'auto';\n    \n    this.preloadedTracks.set(track.id, audio);\n    \n    // Clean up old preloaded tracks (keep only 3)\n    if (this.preloadedTracks.size > 3) {\n      const oldestId = Array.from(this.preloadedTracks.keys())[0];\n      this.preloadedTracks.delete(oldestId);\n    }\n  }\n\n  /**\n   * Enable/disable crossfade\n   */\n  enableCrossfade(enabled: boolean, duration = 3000): void {\n    this.crossfader.setEnabled(enabled);\n    this.crossfader.setDuration(duration);\n  }\n\n  /**\n   * Set volume with smooth transition\n   */\n  setVolume(volume: number, smooth = true): void {\n    const targetVolume = Math.max(0, Math.min(1, volume));\n    \n    if (smooth) {\n      this.smoothVolumeTransition(this.audio.volume, targetVolume);\n    } else {\n      this.audio.volume = targetVolume;\n    }\n    \n    this.emit('volumeChange', { volume: targetVolume });\n  }\n\n  /**\n   * Set playback rate\n   */\n  setPlaybackRate(rate: number): void {\n    this.audio.playbackRate = Math.max(0.25, Math.min(4, rate));\n    this.emit('rateChange', { rate });\n  }\n\n  /**\n   * Get current player state\n   */\n  getState(): AudioPlayerState {\n    return {\n      currentTime: this.audio.currentTime,\n      duration: this.audio.duration || 0,\n      buffered: this.audio.buffered,\n      loading: this.audio.readyState < 3,\n      error: this.audio.error?.message || null,\n      quality: this.qualityAdapter.getCurrentQuality(),\n      volume: this.audio.volume,\n      muted: this.audio.muted,\n      playbackRate: this.audio.playbackRate,\n    };\n  }\n\n  /**\n   * Add event listener\n   */\n  addEventListener(event: string, callback: Function): void {\n    if (!this.eventListeners.has(event)) {\n      this.eventListeners.set(event, []);\n    }\n    this.eventListeners.get(event)!.push(callback);\n  }\n\n  /**\n   * Remove event listener\n   */\n  removeEventListener(event: string, callback: Function): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      const index = listeners.indexOf(callback);\n      if (index > -1) {\n        listeners.splice(index, 1);\n      }\n    }\n  }\n\n  /**\n   * Cleanup resources\n   */\n  destroy(): void {\n    this.audio.pause();\n    this.audio.src = '';\n    this.preloadedTracks.clear();\n    this.eventListeners.clear();\n    this.networkMonitor.destroy();\n  }\n\n  private setupEventListeners(): void {\n    // Standard audio events\n    ['loadstart', 'loadeddata', 'loadedmetadata', 'canplay', 'canplaythrough',\n     'play', 'pause', 'ended', 'error', 'timeupdate', 'progress'].forEach(event => {\n      this.audio.addEventListener(event, () => {\n        this.emit(event, this.getState());\n      });\n    });\n\n    // Network quality monitoring\n    this.networkMonitor.addEventListener('qualityChange', (quality) => {\n      if (this.currentTrack) {\n        this.changeQuality(quality);\n      }\n    });\n  }\n\n  private emit(event: string, data?: any): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      listeners.forEach(callback => callback(data));\n    }\n  }\n\n  private setMediaSessionMetadata(track: AudioTrack): void {\n    if ('mediaSession' in navigator) {\n      navigator.mediaSession.metadata = new MediaMetadata({\n        title: track.title,\n        artist: track.artist,\n        album: track.metadata?.album,\n        artwork: track.metadata?.artwork ? [\n          { src: track.metadata.artwork, sizes: '512x512', type: 'image/png' }\n        ] : undefined,\n      });\n    }\n  }\n\n  private smoothVolumeTransition(from: number, to: number, duration = 300): void {\n    const steps = 20;\n    const stepSize = (to - from) / steps;\n    const stepDuration = duration / steps;\n    let currentStep = 0;\n\n    const interval = setInterval(() => {\n      currentStep++;\n      const newVolume = from + (stepSize * currentStep);\n      this.audio.volume = Math.max(0, Math.min(1, newVolume));\n\n      if (currentStep >= steps) {\n        clearInterval(interval);\n        this.audio.volume = to;\n      }\n    }, stepDuration);\n  }\n}\n\n/**\n * Quality adaptation based on network conditions\n */\nclass QualityAdapter {\n  private currentQuality: keyof AudioTrack['sources'] = 'medium';\n  private networkSpeed: number = 0;\n\n  async getOptimalQuality(track: AudioTrack): Promise<keyof AudioTrack['sources']> {\n    const connection = (navigator as any).connection;\n    \n    if (connection) {\n      const effectiveType = connection.effectiveType;\n      const downlink = connection.downlink;\n      \n      // Adapt quality based on connection\n      if (effectiveType === '4g' && downlink > 10) {\n        return track.sources.lossless ? 'lossless' : 'high';\n      } else if (effectiveType === '4g' || downlink > 5) {\n        return 'high';\n      } else if (effectiveType === '3g' || downlink > 1.5) {\n        return 'medium';\n      } else {\n        return 'low';\n      }\n    }\n    \n    // Fallback to medium quality\n    return 'medium';\n  }\n\n  getCurrentQuality(): keyof AudioTrack['sources'] {\n    return this.currentQuality;\n  }\n\n  setCurrentQuality(quality: keyof AudioTrack['sources']): void {\n    this.currentQuality = quality;\n  }\n}\n\n/**\n * Audio crossfading for smooth transitions\n */\nclass AudioCrossfader {\n  private enabled = false;\n  private duration = 3000;\n\n  setEnabled(enabled: boolean): void {\n    this.enabled = enabled;\n  }\n\n  setDuration(duration: number): void {\n    this.duration = duration;\n  }\n\n  isEnabled(): boolean {\n    return this.enabled;\n  }\n\n  async fadeIn(audio: HTMLAudioElement): Promise<void> {\n    if (!this.enabled) {\n      return audio.play();\n    }\n\n    audio.volume = 0;\n    await audio.play();\n    \n    return new Promise(resolve => {\n      const steps = 20;\n      const stepSize = 1 / steps;\n      const stepDuration = this.duration / steps;\n      let currentStep = 0;\n\n      const interval = setInterval(() => {\n        currentStep++;\n        audio.volume = Math.min(1, stepSize * currentStep);\n\n        if (currentStep >= steps) {\n          clearInterval(interval);\n          resolve();\n        }\n      }, stepDuration);\n    });\n  }\n\n  async fadeOut(audio: HTMLAudioElement): Promise<void> {\n    if (!this.enabled) {\n      audio.pause();\n      return;\n    }\n\n    const originalVolume = audio.volume;\n    \n    return new Promise(resolve => {\n      const steps = 20;\n      const stepSize = originalVolume / steps;\n      const stepDuration = this.duration / steps;\n      let currentStep = 0;\n\n      const interval = setInterval(() => {\n        currentStep++;\n        audio.volume = Math.max(0, originalVolume - (stepSize * currentStep));\n\n        if (currentStep >= steps) {\n          clearInterval(interval);\n          audio.pause();\n          audio.volume = originalVolume;\n          resolve();\n        }\n      }, stepDuration);\n    });\n  }\n}\n\n/**\n * Audio buffer management for optimal streaming\n */\nclass AudioBufferManager {\n  manage(audio: HTMLAudioElement): void {\n    // Monitor buffer health\n    audio.addEventListener('progress', () => {\n      this.checkBufferHealth(audio);\n    });\n\n    audio.addEventListener('waiting', () => {\n      this.handleBufferUnderrun(audio);\n    });\n  }\n\n  private checkBufferHealth(audio: HTMLAudioElement): void {\n    if (audio.buffered.length > 0) {\n      const currentTime = audio.currentTime;\n      const bufferedEnd = audio.buffered.end(audio.buffered.length - 1);\n      const bufferAhead = bufferedEnd - currentTime;\n      \n      // If buffer is low, we might need to adjust quality\n      if (bufferAhead < 10) {\n        console.warn('Low buffer detected:', bufferAhead);\n      }\n    }\n  }\n\n  private handleBufferUnderrun(audio: HTMLAudioElement): void {\n    console.warn('Buffer underrun detected');\n    // Could trigger quality reduction here\n  }\n}\n\n/**\n * Network condition monitoring\n */\nclass NetworkMonitor {\n  private eventListeners: Map<string, Function[]> = new Map();\n  private connection: any;\n\n  constructor() {\n    this.connection = (navigator as any).connection;\n    if (this.connection) {\n      this.connection.addEventListener('change', () => {\n        this.handleConnectionChange();\n      });\n    }\n  }\n\n  addEventListener(event: string, callback: Function): void {\n    if (!this.eventListeners.has(event)) {\n      this.eventListeners.set(event, []);\n    }\n    this.eventListeners.get(event)!.push(callback);\n  }\n\n  destroy(): void {\n    this.eventListeners.clear();\n  }\n\n  private handleConnectionChange(): void {\n    if (this.connection) {\n      const quality = this.getRecommendedQuality();\n      this.emit('qualityChange', quality);\n    }\n  }\n\n  private getRecommendedQuality(): keyof AudioTrack['sources'] {\n    if (!this.connection) return 'medium';\n    \n    const { effectiveType, downlink } = this.connection;\n    \n    if (effectiveType === '4g' && downlink > 10) {\n      return 'high';\n    } else if (effectiveType === '4g' || downlink > 5) {\n      return 'high';\n    } else if (effectiveType === '3g' || downlink > 1.5) {\n      return 'medium';\n    } else {\n      return 'low';\n    }\n  }\n\n  private emit(event: string, data?: any): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      listeners.forEach(callback => callback(data));\n    }\n  }\n}\n\nexport default AudioStreamingPlayer;\n"}